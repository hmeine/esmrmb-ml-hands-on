{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Tutorial \n",
    "## ESMRMB Lecture, Berlin September 2018\n",
    "### Teodora Chitiboi, Sandy Engelhardt, Hans Meine \n",
    "\n",
    "This tutorial provides an introduction into Dense Autoencoders for reconstruction of MRI data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell starts an external tool to download the example data set (this only needs to be done once):\n",
    "\n",
    "> The 20 normal MR brain data sets and their manual\n",
    "  segmentations were provided by the Center for Morphometric Analysis at\n",
    "  Massachusetts General Hospital and are available at\n",
    "  http://www.cma.mgh.harvard.edu/ibsr/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O IBSR_v2_resampled_cropped_8bit_64x64.npz 'https://seafile.zfn.uni-bremen.de/f/15889715dfc7486c87b3/?dl=1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines import required functionality from the [\"keras\"](https://keras.io) and [\"numpy\"](http://www.numpy.org) packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Matplotlib for displaying results and images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibsr_data = np.load('IBSR_v2_resampled_cropped_8bit_64x64.npz')\n",
    "images = ibsr_data['input']\n",
    "print('Dimensions and extents after loading:', images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensions to (NumberOfDatasets, Height, Width)\n",
    "dataset = np.squeeze(images, axis=1);\n",
    "print('Dimensions after dimensionality reduction:', dataset.shape) # should be (2716, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset into train and test (order is already random)\n",
    "x_train = dataset[:2300,:,:]\n",
    "x_test  = dataset[2300:,:,:]\n",
    "\n",
    "# Normalizing images to range [0...1]\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening images into 64*64 = 4096 vector\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print('Flattened dimensions of training data:', x_train.shape)\n",
    "print('Flattened dimensions of testing data: ', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping input vector with factor 128, (32*128 = 4096)\n",
    "encode_dimension = 128\n",
    "\n",
    "# Input placeholder\n",
    "input_img = layers.Input(shape=(4096,))\n",
    "\n",
    "# Encoding of the input\n",
    "encoded_1 = layers.Dense(encode_dimension, activation='relu')(input_img)\n",
    "encoded_2 = layers.Dense(encode_dimension, activation='relu')(encoded_1)\n",
    "\n",
    "# Decoding/reconstruction of the input\n",
    "decoded_1   = layers.Dense(4096, activation='sigmoid')(encoded_2)\n",
    "decoded_2   = layers.Dense(4096, activation='sigmoid')(decoded_1)\n",
    "\n",
    "# This maps the input to its reconstruction\n",
    "# The aim is to fully recover the input image\n",
    "autoencoder = Model(input_img, decoded_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimizer (Adam is a popular choice), and the loss function\n",
    "autoencoder.compile(optimizer = 'adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may read up on further options for the loss (like `mean_absolute_error` or `binary_crossentropy`) at https://keras.io/losses/, and on other optimizers (such as `sgd` or `adadelta`) at https://keras.io/optimizers/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potentially change num_epochs or batch_size\n",
    "num_epochs = 25\n",
    "history = autoencoder.fit(\n",
    "    x_train, x_train,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the autoencoder using the model to predict unseen data\n",
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following code is for displaying of results\n",
    "\n",
    "n = 6 # number of images to display\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(n):\n",
    "    # display image\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    ax.imshow(x_test[i].reshape(64, 64), cmap = 'gray')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_aspect(1.0)\n",
    "\n",
    "    # display reconstructed\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    ax.imshow(decoded_imgs[i].reshape(64, 64), cmap = 'gray')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_aspect(1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
