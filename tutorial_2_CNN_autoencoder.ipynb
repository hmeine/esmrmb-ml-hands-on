{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Tutorial \n",
    "## ESMRMB Lecture, Berlin September 2018\n",
    "### Teodora Chitiboi, Sandy Engelhardt, Hans Meine \n",
    "\n",
    "This tutorial is based on part 1, but uses a CNN Autoencoder.  Let's start with things already known from part 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibsr_data = np.load('IBSR_v2_resampled_cropped_8bit_64x64.npz')\n",
    "images = ibsr_data['input']\n",
    "print('Dimensions and extents after loading:', images.shape)\n",
    "\n",
    "dataset = np.squeeze(images, axis=1);\n",
    "print('Dimensions after dimensionality reduction:', dataset.shape) # should be (2716, 64, 64)\n",
    "\n",
    "# Divide dataset into train and test (order is already random)\n",
    "x_train = dataset[:2300,:,:]\n",
    "x_test  = dataset[2300:,:,:]\n",
    "\n",
    "# Normalizing images to range [0...1]\n",
    "X_Train = x_train.astype('float32') / 255.\n",
    "X_Test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the CNN model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(64, 64, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "# Convolutional layer Kernel 3x3\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "# Max Pooling Kernel 2x2\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "# Convolutional layer Kernel 3x3\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "# Max Pooling  Kernel 2x2\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "# Convolutional layer Kernel 3x3\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "# Max Pooling  Kernel 2x2\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "print('Encoded dimensions should be (8,8,8):', encoded.shape)\n",
    "\n",
    "# Convolutional layer Kernel 3x3\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "# Upsampling Kernel 2x2\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "# Convolutional layer Kernel 3x3\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "# Upsampling Kernel 2x2\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "# Convolutional layer Kernel 3x3\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "# Upsampling Kernel 2x2\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "# Convolutional layer Kernel 3x3\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Set optimizer and loss\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimizer (Adam is a popular choice), and the loss function\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "# further options: loss='mean_squared_error', 'mean_absolute_error'\n",
    "# optimizer='sgd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potentially change num_epochs or batch_size\n",
    "num_epochs = 50\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=num_epochs,\n",
    "                batch_size=16,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the autoencoder using the model to predict unseen data\n",
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following code is for displaying of results\n",
    "\n",
    "n = 6 # number of images to display\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(n):\n",
    "    # display image\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    ax.imshow(x_test[i].reshape(64, 64), cmap = 'gray')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_aspect(1.0)\n",
    "\n",
    "    # display reconstructed\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    ax.imshow(decoded_imgs[i].reshape(64, 64), cmap = 'gray')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_aspect(1.0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
